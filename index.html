<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Faraz Faruqi</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="css/main.css">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar">
        <div class="nav-container">
            <button class="nav-toggle" aria-label="Toggle navigation">
                <span></span>
                <span></span>
                <span></span>
            </button>
            <ul class="nav-menu">
                <li class="nav-item"><a href="index.html" class="nav-link active">about</a></li>
                <li class="nav-item"><a href="publications.html" class="nav-link">publications</a></li>
                <li class="nav-item"><a href="contact.html" class="nav-link">contact</a></li>
                <!-- <li class="nav-item"><a href="blog.html" class="nav-link">blog</a></li> -->
                <!-- <li class="nav-item"><a href="fiction.html" class="nav-link">fiction</a></li> -->
            </ul>
        </div>
    </nav>

    <!-- Main Content -->
    <main class="main-content">
        <div class="container">
            <!-- Header Section -->
            <header class="header-section">
                <h1 class="name-title">Faraz Faruqi</h1>
                <p class="subtitle">PhD Student in Computer Science, MIT CSAIL | Student Researcher, Google XR</p>
            </header>

            <!-- Profile Section -->
            <section class="profile-section">
                <div class="profile-content">
                    <div class="profile-image-container">
                        <img src="img/faraz-headshot.png" alt="Profile Photo" class="profile-image">
                    </div>
                    <div class="bio-text">
                        <p>I am a PhD Candidate in Computer Science at MIT CSAIL, where I work on <b>generative AI systems for 3D design, fabrication, and extended reality (XR)</b>. My research focuses on bridging the gap between visually compelling AI-generated models and physically functional objects that can be manufactured and used in the real world. </p>

                        <br>

                        <p>I am currently a Student Researcher at <a     href="https://xrblocks.github.io/">Google XR Labs</a>, working on 3D generative AI and XR systems. I have also collaborated closely with industry research labs to translate academic ideas into deployable tools. My work has been published at top HCI and fabrication venues (CHI, UIST, SCF) and featured by MIT News.</p>

                        <br>

                        <p>Broadly, I am interested in <b>Physical Generative AI</b> - how we can design AI systems that understand not just appearance, but geometry, materials, forces, and use cases - how these systems can augment human creativity rather than replace it. </p>
                            
                        <br>

                        <p>I develop <b>human-in-the-loop generative systems</b> that integrate physical constraints into 3D generative models, including structural integrity, mechanical behavior, and tactile properties. On the system and HCI side, I explore how users can interactively guide, repair, and refine AI-generated geometry using natural language and spatial interaction, enabling non-experts to create functional designs for real-world use.</p>
                            
                       
                    </div>
                </div>
            </section>

            <!-- Social Links -->
            <section class="social-links">
                <a href="#" class="social-link" title="Resume">
                    <i class="fas fa-file-alt"></i>
                    <span class="social-text">Resume</span>
                </a>
                <a href="#" class="social-link" title="CV">
                    <i class="fas fa-file-pdf"></i>
                    <span class="social-text">CV</span>
                </a>
                <a href="https://scholar.google.com/citations?user=n-9S_B4AAAAJ&hl=en" class="social-link" title="Google Scholar">
                    <i class="fas fa-graduation-cap"></i>
                    <span class="social-text">Scholar</span>
                </a>
                <a href="https://www.linkedin.com/in/faraz-faruqi/" class="social-link" title="LinkedIn">
                    <i class="fab fa-linkedin"></i>
                    <span class="social-text">LinkedIn</span>
                </a>
                <a href="https://x.com/FaruqiFaraz" class="social-link" title="Twitter/X">
                    <i class="fab fa-twitter"></i>
                    <span class="social-text">Twitter</span>
                </a>
            </section>

            <!-- News Section -->
            <section class="news-section">
                <h2 class="section-title">News</h2>
                <table class="news-table">
                    <tbody>
                        <tr>
                            <td class="news-date">Jan 2026</td>
                            <td class="news-content">
                              <strong>Serving as Associate Chair for DIS 2026</strong> - I am serving as an Associate Chair for the Artifacts and Systems subcommittee at <a href="https://dis.acm.org/2026/">ACM DIS 2026</a>, contributing to the review and evaluation of research on interactive systems and tools.
                            </td>
                          </tr>
                          
                        <tr>
                            <td class="news-date">Jan, 2026</td>
                            <td class="news-content">
                                <strong> MechStyle covered in MIT News </strong> - Our work on MechStyle was covered in MIT News. Check out the article <a href="https://news.mit.edu/2026/genai-tool-helps-3d-print-personal-items-sustain-daily-use-0114">here</a>.
                            </td>
                        </tr>
                        <tr>
                            <td class="news-date">Jan, 2026</td>
                            <td class="news-content">
                                <strong> Joined Google XR Labs as a Student Researcher </strong> - I am excited to join the Google XR Labs team as a Student Researcher. I will be working on 3D generative AI and XR systems with <a href="https://duruofei.com/">Ruofei Du</a> and <a href="https://research.google/people/107070/?&type=google">David Kim</a> on the future of 3D Generative AI for XR.
                            </td>
                        </tr>
                        <tr>
                            <td class="news-date">Nov, 2025</td>
                            <td class="news-content">
                                <strong>Presented MechStyle at SCF 2025</strong>
                              - I presented our work on <a href="https://dl.acm.org/doi/10.1145/3745778.3766655">MechStyle</a>, which integrates mechanical simulation into generative 3D workflows to create objects that are both visually compelling and physically functional.
                            </td>
                          </tr>
                          
                          <tr>
                            <td class="news-date">Nov, 2025</td>
                            <td class="news-content">
                              <strong>Presented WireBend-Kit at SCF 2025</strong>
                              - I presented <a href="https://dl.acm.org/doi/10.1145/3745778.3766662">WireBend-Kit</a>, a computational design and fabrication toolkit for wirebending custom 3D wireframe structures.
                            </td>
                          </tr>

                          <tr>
                            <td class="news-date">Oct, 2025</td>
                            <td class="news-content">
                              <strong>Tactile generative art exhibition at the Henry Art Museum</strong>
                              - Presented a public exhibition with <a href="https://martinnisser.com/">Prof. Martin Nisser</a> of University of Washington on <a href="https://dl.acm.org/doi/10.1145/3746058.3758373">3D printed tactile artworks</a> that encode texture and depth, transforming visual images into tactile reliefs using generative AI.
                            </td>
                          </tr>
                          
                    </tbody>
                </table>
            </section>

            <!-- Research Areas Section -->
            <section class="research-section">
                <h2 class="section-title">Research Areas</h2>
                <p class="research-intro">Some recent research themes are highlighted below. For a complete and up-to-date list of papers, please see my Google Scholar page.</p>
                
                <div class="research-areas">
                    <div class="research-area">
                        <h3 class="research-area-title">Physical Generative AI for Fabrication</h3>
                        <p class="research-area-description">
                            I design generative AI systems that create physically viable 3D objects rather than purely visual geometry. My work integrates fabrication constraints—such as structural integrity, material behavior, thickness, and manufacturability—directly into generative pipelines. Through systems like Style2Fab, MechStyle, and TactStyle, I explore how AI can reason about function alongside form, enabling non-experts to generate objects that can be reliably fabricated and used in the real world.
                        </p>
                    </div>
                    
                    <div class="research-area">
                        <h3 class="research-area-title">Human-in-the-Loop Generative Systems</h3>
                        <p class="research-area-description">
                            I study how humans can effectively steer, repair, and collaborate with generative AI systems. My research focuses on building interactive workflows that combine natural language, spatial input, and selective control to guide AI outputs toward user intent. Rather than one-shot prompting, I design mixed-initiative systems that allow users to iteratively refine generative results—particularly when correcting functional or fabrication-related errors.
                        </p>    
                    </div>
                    
                    <div class="research-area">
                        <h3 class="research-area-title">Multimodal & In-Situ 3D Design in XR</h3>
                        <p class="research-area-description">
                            I explore how multimodal interaction—combining natural language, spatial input, gestures, and visual context—can enable in-situ 3D design within extended reality (XR) environments. My research investigates how users can create, inspect, and refine generative 3D models directly in context, rather than through detached desktop workflows. By integrating generative AI with XR interfaces, I aim to support more intuitive, iterative, and embodied design processes that allow creators to reason about form, function, and physical constraints while designing in place.
                        </p>
                    </div>
                </div>
                
            </section>
        </div>
    </main>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>&copy; Copyright <span id="current-year"></span> Your Name. Powered by HTML, CSS, and JavaScript.</p>
        </div>
    </footer>

    <script src="js/main.js"></script>
</body>
</html>


