<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Media - Faraz Faruqi</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="css/main.css">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar">
        <div class="nav-container">
            <button class="nav-toggle" aria-label="Toggle navigation">
                <span></span>
                <span></span>
                <span></span>
            </button>
            <ul class="nav-menu">
                <li class="nav-item"><a href="index.html" class="nav-link">About</a></li>
                <li class="nav-item"><a href="publications.html" class="nav-link">Publications</a></li>
                <li class="nav-item"><a href="teaching.html" class="nav-link">Teaching</a></li>
                <li class="nav-item"><a href="media.html" class="nav-link active">Media</a></li>
                <li class="nav-item"><a href="contact.html" class="nav-link">Contact</a></li>
                <!-- <li class="nav-item"><a href="blog.html" class="nav-link">blog</a></li> -->
                <!-- <li class="nav-item"><a href="fiction.html" class="nav-link">fiction</a></li> -->
            </ul>
        </div>
    </nav>

    <!-- Main Content -->
    <main class="main-content">
        <div class="container">
            <header class="header-section">
                <h1 class="name-title">Media</h1>
            </header>

            <section class="media-section">
                <h2>Exhibitions & Public Showcases</h2>

                <div class="exhibition">
                    <div class="exhibition-header" onclick="toggleExhibition(this)">
                        <div class="exhibition-header-content">
                            <h3>Art You Can Touch: Transforming Paintings into Touchable 3D Reliefs with Generative AI</h3>
                            <p class="exhibition-meta">
                                Henry Art Gallery · Seattle, WA · 2025
                            </p>
                            <p class="exhibition-meta">
                                <strong>Organiser</strong> · In collaboration with <a href="https://people.csail.mit.edu/nisser/">Prof. Martin Nisser</a>. <br> Photo credit: <a href="https://www.instagram.com/everythingtimestudio/">Everything Time Studio</a> 
                            </p>
                        </div>
                        <i class="fas fa-chevron-down exhibition-chevron"></i>
                    </div>
                    <div class="exhibition-content collapsed">
                        <p>
                            This exhibition presents a series of tactile 3D-printed reliefs that translate paintings and images into touchable physical artifacts. Using generative AI and computational fabrication techniques, the work explores how visual media can be transformed into objects that convey texture, depth, and material presence through touch.

                            The pieces invite visitors to engage with images beyond sight alone, offering an alternative way of experiencing visual content that foregrounds physical interaction, accessibility, and material understanding.
                        </p>

                        <div class="exhibition-gallery">
                            <img src="img/Henry_Art_Gallery/henry-kids.png" alt="3D printed tactile tile with layered texture" class="gallery-image">
                            <img src="img/Henry_Art_Gallery/henry-objects.png" alt="Close-up of generative texture patterns" class="gallery-image">
                            <img src="img/Henry_Art_Gallery/henry-poster.png" alt="Poster with details about the exhibition" class="gallery-image">
                            <img src="img/Henry_Art_Gallery/henry-more-objects.png" alt="More images from the exhibition" class="gallery-image">
                        </div>
                    </div>
                </div>

                <div class="exhibition">
                    <div class="exhibition-header" onclick="toggleExhibition(this)">
                        <div class="exhibition-header-content">
                            <h3>RSS 2025 Workshop on Navigating Contact Dynamics in Robotics</h3>
                            <p class="exhibition-meta">
                                RSS 2025 · University of Southern California · June 2025
                            </p>
                            <p class="exhibition-meta">
                                <strong>Invited Speaker</strong> 
                            </p>
                        </div>
                        <i class="fas fa-chevron-down exhibition-chevron"></i>
                    </div>
                    <div class="exhibition-content collapsed">
                        <p>
                            I was invited to present and demonstrate my work on tactile surface generation and fabrication-aware generative models at the <a href="https://sites.google.com/colorado.edu/ws-contact-dynamics/home?authuser=0">Navigating Contact Dynamics in Robotics workshop</a> at <a href="https://roboticsconference.org/">RSS 2025</a>. The workshop brought together researchers across robotics, haptics, and interaction to explore how contact, material properties, and physical dynamics shape intelligent systems for Physical AI.
                        </p>

                        <div class="exhibition-gallery">
                            <img src="img/RSS_Workshop/rss-conference-1.jpg" alt="Workshop presentation at RSS 2025" class="gallery-image">
                            <img src="img/RSS_Workshop/rss-conference-2.jpg" alt="Organizing team and inviting speakers to the workshop" class="gallery-image">
                            <img src="img/RSS_Workshop/rss-conference-3.jpeg" alt="Faraz presenting his work at the workshop" class="gallery-image">
                            <img src="img/RSS_Workshop/rss-conference-4.jpeg" alt="Tactile surface for robotic perception" class="gallery-image">
                        </div>
                    </div>
                </div>
            </section>

            <section class="media-section">
                <h2>News Articles</h2>

                <div class="news-article">
                    <div class="news-article-content">
                        <div class="news-article-header">
                            <h3 class="news-article-title">Generative AI tool helps 3D print personal items that sustain daily use</h3>
                            <p class="news-article-meta">MIT News | Massachusetts Institute of Technology · January 14, 2026</p>
                        </div>
                        <div class="news-article-preview">
                            <div class="news-article-image">
                                <img src="img/news-images/mechstyle-news-image.jpg" alt="MechStyle: AI-powered 3D printing system" class="news-preview-image">
                            </div>
                            <div class="news-article-text">
                                <p class="news-article-description">MechStyle, a system developed at MIT, enables users to upload a 3D model or preset asset of everyday items, then prompt a generative AI model using images or text to personalize it. The system keeps the design structurally sound before it's 3D printed.
                                </p>
                                <p class="news-article-link">
                                    <a href="https://news.mit.edu/2026/genai-tool-helps-3d-print-personal-items-sustain-daily-use-0114" target="_blank" rel="noopener noreferrer" class="news-article-url">Read full article →</a>
                                </p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="news-article">
                    <div class="news-article-content">
                        <div class="news-article-header">
                            <h3 class="news-article-title">3D modeling you can feel</h3>
                            <p class="news-article-meta">MIT News | Massachusetts Institute of Technology · April 22, 2025</p>
                        </div>
                        <div class="news-article-preview">
                            <div class="news-article-image">
                                <img src="img/news-images/tactstyle-mit-news.jpg" alt="TactStyle: 3D modeling system" class="news-preview-image">
                            </div>
                            <div class="news-article-text">
                                <p class="news-article-description">MIT CSAIL's "TactStyle" system uses image prompts to replicate both the visual appearance and touch-based properties of 3D models. It could help create home décor, personal accessories, and tactile learning tools from a single image input.</p>
                                <p class="news-article-link">
                                    <a href="https://news.mit.edu/2025/3d-modeling-you-can-feel-0422" target="_blank" rel="noopener noreferrer" class="news-article-url">Read full article →</a>
                                </p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="news-article">
                    <div class="news-article-content">
                        <div class="news-article-header">
                            <h3 class="news-article-title">Making 3D Printing Personal: How Faraz Faruqi Is Rethinking Digital Design at MIT CSAIL - 3DPrint.com | Additive Manufacturing Business</h3>
                            <p class="news-article-meta">3DPrint.com | Additive Manufacturing Business · July 2, 2025</p>
                        </div>
                        <div class="news-article-preview">
                            <div class="news-article-image">
                                <img src="img/news-images/tactstyle-mit-news.jpg" alt="3D printing personalization" class="news-preview-image">
                            </div>
                            <div class="news-article-text">
                                <p class="news-article-description">What if your 3D printer could think more like an intelligent assistant, able to reason through a design idea, ask questions, and deliver something that works exactly the way the user envisioned it? That's the kind of future Faraz Faruqi, a senior PhD student at MIT's Computer Science and Artificial Intelligence Lab (CSAIL), is working toward. And for Faruqi, it's not just about technical breakthroughs: it's about making 3D printing personal, intuitive, and radically more inclusive.</p>
                                <p class="news-article-link">
                                    <a href="https://3dprint.com/318739/making-3d-printing-personal-how-faraz-faruqi-is-rethinking-digital-design-at-mit-csail" target="_blank" rel="noopener noreferrer" class="news-article-url">Read full article →</a>
                                </p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="news-article">
                    <div class="news-article-content">
                        <div class="news-article-header">
                            <h3 class="news-article-title">AI-driven tool makes it easy to personalize 3D-printable models</h3>
                            <p class="news-article-meta">MIT News | Massachusetts Institute of Technology · September 15, 2023</p>
                        </div>
                        <div class="news-article-preview">
                            <div class="news-article-image">
                                <img src="img/news-images/style2fab-mit-news.jpg" alt="Style2Fab: AI-driven 3D printing tool" class="news-preview-image">
                            </div>
                            <div class="news-article-text">
                                <p class="news-article-description">MIT researchers developed a user-friendly interface that enables a maker to customize the color, texture, and shape of the aesthetic characteristics of an open-source 3D model from an online repository, without affecting the functionality of the fabricated object.</p>
                                <p class="news-article-link">
                                    <a href="https://news.mit.edu/2023/ai-driven-tool-personalize-3d-printable-models-0915" target="_blank" rel="noopener noreferrer" class="news-article-url">Read full article →</a>
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
                
            </section>
        </div>
    </main>

    <!-- Lightbox Modal -->
    <div id="lightbox" class="lightbox">
        <span class="lightbox-close">&times;</span>
        <img class="lightbox-image" id="lightbox-image" src="" alt="">
        <div class="lightbox-caption" id="lightbox-caption"></div>
    </div>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>&copy; Copyright <span id="current-year"></span> Faraz Faruqi</p>
        </div>
    </footer>

    <script src="js/main.js"></script>
</body>
</html>

